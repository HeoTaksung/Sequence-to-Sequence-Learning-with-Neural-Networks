{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM,Dense,Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import keras\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=[]\n",
    "output_data = []\n",
    "\n",
    "file = open('./fra.txt', 'r', encoding='utf-8-sig')\n",
    "\n",
    "for idx, line in enumerate(file):\n",
    "    if idx == 100000:\n",
    "        break\n",
    "    line = line.split('\\t')\n",
    "    input_data.append(line[0])\n",
    "    output_data.append('\\t' + line[1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_max_seq = max([len(text) for text in input_data])\n",
    "output_max_seq = max([len(text) for text in output_data])\n",
    "input_voc_size = 0\n",
    "output_voc_size = 0\n",
    "embedding_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_voc = set()\n",
    "output_voc = set()\n",
    "for ii,[input_text,output_text] in enumerate(zip(input_data,output_data)):\n",
    "    for word in input_text:\n",
    "        input_voc.add(word)\n",
    "    for word in output_text:\n",
    "        output_voc.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_voc = sorted(input_voc)\n",
    "output_voc = sorted(output_voc)\n",
    "input_voc_size = len(input_voc)\n",
    "output_voc_size = len(output_voc)\n",
    "data_size = len(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_num = {name:num for num,name in enumerate(input_voc)}\n",
    "output_to_num = {name:num for num,name in enumerate(output_voc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_datas = np.zeros((data_size,input_max_seq,input_voc_size),dtype = 'float32')\n",
    "decoder_input_datas= np.zeros((data_size,output_max_seq,output_voc_size),dtype = 'float32')\n",
    "decoder_output_datas = np.zeros((data_size,output_max_seq,output_voc_size),dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii,[input_text,output_text] in enumerate(zip(input_data,output_data)):\n",
    "    for t,text in enumerate(input_text):\n",
    "        encoder_input_datas[ii,t,input_to_num[text]] = 1.\n",
    "    for t,text in enumerate(output_text):\n",
    "        decoder_input_datas[ii,t,output_to_num[text]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_output_datas[ii,t-1,output_to_num[text]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 79)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 106)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 344064      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  371712      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 106)    27242       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 743,018\n",
      "Trainable params: 743,018\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input((input_max_seq,input_voc_size))\n",
    "encoder_lstm = LSTM(embedding_size,return_state=True)\n",
    "encodet_outputs,state_h,state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_state = [state_h,state_c]\n",
    "\n",
    "decoder_inputs = Input((None,output_voc_size))\n",
    "decoder_lstm = LSTM(embedding_size,return_sequences= True, return_state= True)\n",
    "decoder_outputs,_,_ = decoder_lstm(decoder_inputs,initial_state = encoder_state)\n",
    "decoder_dense = Dense(output_voc_size,activation=\"softmax\")\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "80000/80000 [==============================] - 205s 3ms/step - loss: 0.6643 - val_loss: 0.6974\n",
      "Epoch 2/50\n",
      "80000/80000 [==============================] - 199s 2ms/step - loss: 0.4549 - val_loss: 0.5678\n",
      "Epoch 3/50\n",
      "80000/80000 [==============================] - 199s 2ms/step - loss: 0.3867 - val_loss: 0.5025\n",
      "Epoch 4/50\n",
      "80000/80000 [==============================] - 199s 2ms/step - loss: 0.3471 - val_loss: 0.4707\n",
      "Epoch 5/50\n",
      "80000/80000 [==============================] - 198s 2ms/step - loss: 0.3215 - val_loss: 0.4467\n",
      "Epoch 6/50\n",
      "80000/80000 [==============================] - 199s 2ms/step - loss: 0.3034 - val_loss: 0.4303\n",
      "Epoch 7/50\n",
      "80000/80000 [==============================] - 201s 3ms/step - loss: 0.2898 - val_loss: 0.4203\n",
      "Epoch 8/50\n",
      "80000/80000 [==============================] - 202s 3ms/step - loss: 0.2786 - val_loss: 0.4128\n",
      "Epoch 9/50\n",
      "80000/80000 [==============================] - 202s 3ms/step - loss: 0.2694 - val_loss: 0.4075\n",
      "Epoch 10/50\n",
      "80000/80000 [==============================] - 200s 2ms/step - loss: 0.2616 - val_loss: 0.4017\n",
      "Epoch 11/50\n",
      "80000/80000 [==============================] - 199s 2ms/step - loss: 0.2547 - val_loss: 0.3977\n",
      "Epoch 12/50\n",
      "80000/80000 [==============================] - 198s 2ms/step - loss: 0.2487 - val_loss: 0.3945\n",
      "Epoch 13/50\n",
      "80000/80000 [==============================] - 201s 3ms/step - loss: 0.2433 - val_loss: 0.3936\n",
      "Epoch 14/50\n",
      "80000/80000 [==============================] - 201s 3ms/step - loss: 0.2385 - val_loss: 0.3928\n",
      "Epoch 15/50\n",
      "80000/80000 [==============================] - 201s 3ms/step - loss: 0.2341 - val_loss: 0.3910\n",
      "Epoch 16/50\n",
      "80000/80000 [==============================] - 200s 3ms/step - loss: 0.2300 - val_loss: 0.3895\n",
      "Epoch 17/50\n",
      "80000/80000 [==============================] - 200s 3ms/step - loss: 0.2262 - val_loss: 0.3886\n",
      "Epoch 18/50\n",
      "80000/80000 [==============================] - 200s 3ms/step - loss: 0.2227 - val_loss: 0.3898\n",
      "Epoch 19/50\n",
      "80000/80000 [==============================] - 202s 3ms/step - loss: 0.2195 - val_loss: 0.3881\n",
      "Epoch 20/50\n",
      "80000/80000 [==============================] - 200s 2ms/step - loss: 0.2164 - val_loss: 0.3883\n",
      "Epoch 21/50\n",
      "80000/80000 [==============================] - 201s 3ms/step - loss: 0.2136 - val_loss: 0.3889\n",
      "Epoch 22/50\n",
      "80000/80000 [==============================] - 200s 3ms/step - loss: 0.2109 - val_loss: 0.3917\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00022: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0381cf2358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.utils.multi_gpu_model(model, gpus=3)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',mode='min', verbose=1, patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit([encoder_input_datas,decoder_input_datas],decoder_output_datas,\n",
    "          batch_size = batch_size,\n",
    "          epochs = 50,validation_split=0.2, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs,encoder_state)\n",
    "decoder_input_h = Input(shape = (embedding_size,))\n",
    "decoder_input_c = Input(shape = (embedding_size,))\n",
    "decoder_input_state = [decoder_input_h,decoder_input_c]\n",
    "\n",
    "decoder_outputs,state_h,state_c = decoder_lstm(decoder_inputs,initial_state=decoder_input_state)\n",
    "\n",
    "decoder_states = [state_h,state_c]\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_input_state,[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1,output_voc_size))\n",
    "    target_seq[0,0,output_to_num['\\t']] = 1.\n",
    "    stop_condition = False\n",
    "    decode_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens,h,c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0,0,:])\n",
    "        \n",
    "        sampled_char = output_to_char[sampled_token_index]\n",
    "        decode_sentence+=sampled_char\n",
    "        \n",
    "        if(sampled_char == '\\n' or len(decode_sentence) > output_max_seq):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1,1,output_voc_size))\n",
    "        target_seq[0,0,output_to_num[sampled_char]] = 1.\n",
    "        states_value = [h,c]\n",
    "    \n",
    "    return decode_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_char = {ii:nn for ii,nn in enumerate(input_voc)}\n",
    "output_to_char = {ii:nn for ii,nn in enumerate(output_voc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 :  Go.\n",
      "정답 :  Va !\n",
      "모델 :  Continuez !\n",
      "\n",
      "입력 :  Hi.\n",
      "정답 :  Salut !\n",
      "모델 :  Salut.\n",
      "\n",
      "입력 :  Hi.\n",
      "정답 :  Salut.\n",
      "모델 :  Salut.\n",
      "\n",
      "입력 :  Run!\n",
      "정답 :  Cours !\n",
      "모델 :  Coupe !\n",
      "\n",
      "입력 :  Run!\n",
      "정답 :  Courez !\n",
      "모델 :  Coupe !\n",
      "\n",
      "입력 :  Who?\n",
      "정답 :  Qui ?\n",
      "모델 :  Qui s'est passée ?\n",
      "\n",
      "입력 :  Wow!\n",
      "정답 :  Ça alors !\n",
      "모델 :  Dis le main.\n",
      "\n",
      "입력 :  Fire!\n",
      "정답 :  Au feu !\n",
      "모델 :  Pas de mon !\n",
      "\n",
      "입력 :  Help!\n",
      "정답 :  À l'aide !\n",
      "모델 :  À l'argent !\n",
      "\n",
      "입력 :  Jump.\n",
      "정답 :  Saute.\n",
      "모델 :  Fais-en une manière.\n",
      "\n",
      "입력 :  Stop!\n",
      "정답 :  Ça suffit !\n",
      "모델 :  Arrêtez !\n",
      "\n",
      "입력 :  Stop!\n",
      "정답 :  Stop !\n",
      "모델 :  Arrêtez !\n",
      "\n",
      "입력 :  Stop!\n",
      "정답 :  Arrête-toi !\n",
      "모델 :  Arrêtez !\n",
      "\n",
      "입력 :  Wait!\n",
      "정답 :  Attends !\n",
      "모델 :  Attendez !\n",
      "\n",
      "입력 :  Wait!\n",
      "정답 :  Attendez !\n",
      "모델 :  Attendez !\n",
      "\n",
      "입력 :  Go on.\n",
      "정답 :  Poursuis.\n",
      "모델 :  Va chercher !\n",
      "\n",
      "입력 :  Go on.\n",
      "정답 :  Continuez.\n",
      "모델 :  Va chercher !\n",
      "\n",
      "입력 :  Go on.\n",
      "정답 :  Poursuivez.\n",
      "모델 :  Va chercher !\n",
      "\n",
      "입력 :  Hello!\n",
      "정답 :  Bonjour !\n",
      "모델 :  À l'argent !\n",
      "\n",
      "입력 :  Hello!\n",
      "정답 :  Salut !\n",
      "모델 :  À l'argent !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    input_seq = encoder_input_datas[i:i+1]\n",
    "    print(\"입력 : \", input_data[i])\n",
    "    print(\"정답 : \", output_data[i][1:-1])\n",
    "    print(\"모델 : \", decode_sequence(input_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
